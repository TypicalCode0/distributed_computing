# Отчёт по лабораторной работе (MPI)

### Установка нужных библиотек
```bash
sudo apt update  
sudo apt install openmpi-bin openmpi-doc libopenmpi-dev python3-pandas python3-matplotlib python3-numpy -y
```
### Запуск экспериментов (пример)
в корне проекта:
```bash
./utils/run_experiments_1.sh
./utils/run_experiments_2.sh
./utils/run_experiments_3.sh
```

## Задание 1 — вычисление π методом Монте-Карло

**Условия**
- процессы: `1 4 8`  
- выборки: `10^6 15*10^5 10^7 15*10^6 2*10^7`  
- повторов на конфигурацию: `3`

**Графики**  
- Ускорение
  
![Иллюстрация к проекту](https://github.com/TypicalCode0/distributed_computing/blob/main/utils/graphics_1/speedup.png)    
- Эффективность (ускорение/количество процессоров)
  
![Иллюстрация к проекту](https://github.com/TypicalCode0/distributed_computing/blob/main/utils/graphics_1/efficiency.png)  

**Наблюдения**
- Ускорение при увеличении числа процессов растёт почти линейно
- Эффективность высока: при 4 процессах она почти равна 1, при 8 процессах в среднем 0.9
- Для больших объёмов выборкипараллельная реализация демонстрирует ближе к идеальному масштабированию
- Эффективность в одном измерении превышает 1, но это можно списать на нестабильность данных в силу небольшого количества данных


**Вывод**
- Метод Монте-Карло для оценки π хорошо распараллеливается, емееет высокие эффективность и ускорение

## Задание 2 — умножение матрицы на вектор

**Режимы тестирования**
- `row` (разбиение по строкам)  
- `col` (разбиение по столбцам)  
- `block` (блочное разбиение / сетка процессов)  
**Условия**
- процессы: `1 4 8`  
- выборки: `10^3 5*10^3 10^4`  
- повторов на конфигурацию: `3`

**Графики**  
- Ускорение

![Иллюстрация к проекту](https://github.com/TypicalCode0/distributed_computing/blob/main/utils/graphics_2/speedup_row.png)    
![Иллюстрация к проекту](https://github.com/TypicalCode0/distributed_computing/blob/main/utils/graphics_2/speedup_col.png)  
![Иллюстрация к проекту](https://github.com/TypicalCode0/distributed_computing/blob/main/utils/graphics_2/speedup_block.png)  
- Эффективность (ускорение/количество процессоров)
  
![Иллюстрация к проекту](https://github.com/TypicalCode0/distributed_computing/blob/main/utils/graphics_2/efficiency_row.png)  
![Иллюстрация к проекту](https://github.com/TypicalCode0/distributed_computing/blob/main/utils/graphics_2/efficiency_col.png)  
![Иллюстрация к проекту](https://github.com/TypicalCode0/distributed_computing/blob/main/utils/graphics_2/efficiency_block.png)  


**Наблюдения**

Для всех трех алгоритмов ускорение растет с увеличением числа процессов. Однако этот рост не является линейным (отстает от красной пунктирной линии "ideal linear"). Это связано с наличием накладных расходов на параллелизм (коммуникации, синхронизация).

Увеличение размера задачи (параметр size с 1000 до 10000) значительно улучшает и ускорение, и эффективность для всех трех алгоритмов.

row (декомпозиция по строкам):

- Показывает стабильно хорошие результаты.

- На малом размере (size=1000) этот метод самый эффективный из трех (эффективность ~0.48 при 8 процессах).

- На больших размерах (size=10000) он лишь немного уступает методу col (эффективность ~0.58).

col (декомпозиция по столбцам):

- Показывает лучшую эффективность и ускорение для больших матриц (size=10000, эффективность ~0.61 при 8 процессах).

- Однако он показывает худшую производительность для малой матрицы (size=1000, эффективность всего ~0.30 при 8 процессах).

block (блочная декомпозиция):

- На малом размере (size=1000) так же неэффективен, как и col (~0.31).

- На больших размерах (size=5000, size=10000) он показывает неплохую, но слегка уступающую двум другим методам эффективность (~0.55).

**Вывод**

- Влияние размера задачи: Это главный фактор. Увеличение size (с 1000 до 10000) резко повышает эффективность всех трех методов. Это происходит потому, что объем вычислений O(N^2) растет быстрее, чем объем коммуникаций O(N).Влияние числа процессов: Увеличение числа процессов снижает эффективность для всех алгоритмов, так как растут накладные расходы на коммуникацию.
  
- row (строчный) - самый стабильный и сбалансированный алгоритм. Показывает хорошие результаты для всех размеров, особенно для малого (size=1000).
- col (столбцовый) - лучший для больших матриц (size=10000), но провальный для малых (size=1000). Его узкое место — сборка (MPI_Reduce) полного вектора-результата, что дорого при малом $N$.
- block (блочный): Самый медленный в данных тестах (до 8 процессов). Его коммуникационная схема (2D-топология) слишком сложна и неэффективна при малом числе процессов.

## Задание 3 — умножение матриц (алгоритм Кэннона)

Алгоритм заключается 
в распределении матриц по квадратной сетке процессов с последующими 
циклическими сдвигами блоков.

Из процессов строится квадратная сетка sqrt(p) на sqrt(p), где p - количество процессов

Теор. вычислительная сложность: O(N^3/p)

Теор. коммуникационная сложность: O(P*x + y * N^2/p)

,где 
x - задержка передачи процесса, y - передача блока


**Условия**
- число процессов: полный квадрат (`1 4 9`)  
- `n` должно делиться на `sqrt(p)`
- выборки: `6*10^2 12*10^2 15*10^2`
- повторов на конфигурацию: `3`

**Графики**  
- Ускорение
    
![Иллюстрация к проекту](https://github.com/TypicalCode0/distributed_computing/blob/main/utils/graphics_3/speedup.png)    
- Эффективность (ускорение/количество процессоров)
  
![Иллюстрация к проекту](https://github.com/TypicalCode0/distributed_computing/blob/main/utils/graphics_3/efficiency.png)  

**Наблюдения**
- Почти линейное ускорение на малом количестве процессов (до 4) - кривые для всех размеров матриц растут близко к идеальной линии, 
что указывает на равномерное распределение нагрузки между процессами и низкие расходы на коммуникации
- При увеличении числа процессов рост ускорения для малых матриц (600) замедляется: связано с тем, что размер локальных 
блоков уменьшается (N^2/p) и доля коммуникации становится заметнее относительно вычислений
- Для матриц размером 1200 и 1500 при 9 процессах ускорение выше и ближе к идеальному, 
поскольку вычислительная часть растет кубически (N^3), что перевешивает коммуникационную квадратичную часть (N^2)

**Вывод**
- Алгоритм Кэннона реализован корректно: наблюдается линейное ускорение на малом числе процессов и предсказуемое снижение эффективности при масштабировании
- Экспериментальные результаты подтверждают теоретические оценки вычислительной и коммуникационной сложности алгоритма Кэннона
